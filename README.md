# Context-Dependent Speech Emotion Recognition Using Recurrent Neural Networks (RNN)

Human and computer interaction continues to develop to the most natural form possible. In human interaction, emotion plays an important role in the information delivered. Therefore, emotion has to be involved in the development of human-computer interaction.

Speech emotion recognition has been developed to predict an emotion contained in an utterance. Current research considers utterances as independent entities, i.e. ignores the inter-dependencies and relations among the utterances of a conversation. While in human interaction, we as a human can also recognize emotion in a conversation that consist of sequence of utterances.

In order to achieve the nature of human-computer interaction, we develop context-based speech emotion recognition using Recurrent Neural Network (RNN). The model receive a sequence of utterance as an input, and catches the dependencies utterances to predict emotion in conversation. There are 6 emotions included: happiness, sadness, angry, fear, surprise, and disgust. 
